{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Yelp Data Challenge - NLP\n",
    "\n",
    "Yiting Luo | Data Science Applied Research - 2\n",
    "\n",
    "May 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/last_2_years_restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Cajun/Creole', 'Steakhouses', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>6SgvNWJltnZhW7duJgZ42w</td>\n",
       "      <td>5</td>\n",
       "      <td>This is mine and my fiancé's favorite steakhou...</td>\n",
       "      <td>0</td>\n",
       "      <td>oFyOUOeGTRZhFPF9uTqrTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Cajun/Creole', 'Steakhouses', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>0</td>\n",
       "      <td>iwx6s6yQxc7yjS7NFANZig</td>\n",
       "      <td>4</td>\n",
       "      <td>Nice atmosphere and wonderful service. I had t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2aeNFntqY2QDZLADNo8iQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Cajun/Creole', 'Steakhouses', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>0</td>\n",
       "      <td>UVUMu_bELdA56Ryfbur-DA</td>\n",
       "      <td>5</td>\n",
       "      <td>Every year a group of us (we had 6 this year) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gmPP4YFrgYsYQqPYokMgFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Cajun/Creole', 'Steakhouses', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-10</td>\n",
       "      <td>0</td>\n",
       "      <td>UxFpgng8dPMWOj99653k5Q</td>\n",
       "      <td>5</td>\n",
       "      <td>Truly Fantastic!  Best Steak ever. Service was...</td>\n",
       "      <td>0</td>\n",
       "      <td>aVOGlN9fZ-BXcbtj6dbf0g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Cajun/Creole', 'Steakhouses', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>Xp3ppynEvVu1KxDHQ3ae8w</td>\n",
       "      <td>5</td>\n",
       "      <td>Delmonico Steakhouse is a steakhouse owned by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>KC8H7qTZVPIEnanw9fG43g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                  name  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "\n",
       "                                       categories  avg_stars  cool  \\\n",
       "0  ['Cajun/Creole', 'Steakhouses', 'Restaurants']        4.0     0   \n",
       "1  ['Cajun/Creole', 'Steakhouses', 'Restaurants']        4.0     0   \n",
       "2  ['Cajun/Creole', 'Steakhouses', 'Restaurants']        4.0     0   \n",
       "3  ['Cajun/Creole', 'Steakhouses', 'Restaurants']        4.0     0   \n",
       "4  ['Cajun/Creole', 'Steakhouses', 'Restaurants']        4.0     0   \n",
       "\n",
       "         date  funny               review_id  stars  \\\n",
       "0  2016-03-31      0  6SgvNWJltnZhW7duJgZ42w      5   \n",
       "1  2015-06-29      0  iwx6s6yQxc7yjS7NFANZig      4   \n",
       "2  2015-03-16      0  UVUMu_bELdA56Ryfbur-DA      5   \n",
       "3  2016-02-10      0  UxFpgng8dPMWOj99653k5Q      5   \n",
       "4  2017-02-14      0  Xp3ppynEvVu1KxDHQ3ae8w      5   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  This is mine and my fiancé's favorite steakhou...       0   \n",
       "1  Nice atmosphere and wonderful service. I had t...       0   \n",
       "2  Every year a group of us (we had 6 this year) ...       1   \n",
       "3  Truly Fantastic!  Best Steak ever. Service was...       0   \n",
       "4  Delmonico Steakhouse is a steakhouse owned by ...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  oFyOUOeGTRZhFPF9uTqrTQ  \n",
       "1  2aeNFntqY2QDZLADNo8iQQ  \n",
       "2  gmPP4YFrgYsYQqPYokMgFA  \n",
       "3  aVOGlN9fZ-BXcbtj6dbf0g  \n",
       "4  KC8H7qTZVPIEnanw9fG43g  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your feature variables, here is the text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents\"\n",
    "documents = df['text'].values  # Make results to Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('O'), (515752,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect your documents, e.g. check the size, take a peek at elements of the numpy array\n",
    "documents.dtype, documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Truly Fantastic!  Best Steak ever. Service was awesome and timely. They knew right when you needed something. The root beer float for dessert was great.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define target variable (any categorical variable that may be meaningful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am interested in perfect (5 stars) and imperfect (1-4 stars) rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a column and take the values, save to a variable named \"target\"\n",
    "df['favorable'] = (df['stars'] > 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = df['favorable'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True,  True, False,  True,  True,  True,\n",
       "       False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the statistic of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46397299477268145, 0.49870036584541505, (515752,), (515752,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To be implemented\n",
    "target.mean(), target.std(), documents.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create training dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyiting/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Documents is X, target is y\n",
    "# Now split the data to training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to documents_train, documents_test, target_train, target_test\n",
    "documents_train, documents_test, target_train, target_test = train_test_split(\n",
    "    documents, target, test_size = 0.8, random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get NLP representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyiting/anaconda/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# Train the model with training data\n",
    "vectors_train = vectorizer.fit_transform(documents_train).toarray() # toarray avoid sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the vocab of tfidf\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103150, 5000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyiting/anaconda/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to transform your test data\n",
    "vectors_test = vectorizer.transform(documents_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar review search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"cat\", \"pig\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[::-1][:n]]  # np.argsort by default sorts values in ascending order\n",
    "\n",
    "def get_bottom_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the lowest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"mouse\", \"rabbit\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[:n]] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's use cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great food and great price, the only thing is the waiting time. During lunch and dinner hours, they are extremely busy. Call in ahead to get your order and pick up for faster service :)\n",
      "['Great food and great price, the only thing is the waiting time. During lunch and dinner hours, they are extremely busy. Call in ahead to get your order and pick up for faster service :)']\n"
     ]
    }
   ],
   "source": [
    "# Draw an arbitrary review from test (unseen in training) documents\n",
    "some_random_number = 42\n",
    "search_query = documents_test[some_random_number]\n",
    "search_queries = [search_query]\n",
    "print (search_query)\n",
    "print (search_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyiting/anaconda/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# Transform the drawn review(s) to vector(s)\n",
    "vector_search_queries = vectorizer.transform(search_queries).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity score(s) between vector(s) and training vectors\n",
    "similarity_score = cosine_similarity(vector_search_queries, vectors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 103150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's find top 5 similar reviews\n",
    "n = 5\n",
    "returned_reviews = get_top_values(similarity_score[0], n, documents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our search query:\n",
      "Great food and great price, the only thing is the waiting time. During lunch and dinner hours, they are extremely busy. Call in ahead to get your order and pick up for faster service :)\n"
     ]
    }
   ],
   "source": [
    "print ('Our search query:')\n",
    "print  (search_queries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most 5 similar reviews:\n",
      "Great buffet and a great price. Ive eaten here 4 times. It was great each time. It can get busy though so i would suggest call ahead to find out the wait time\n",
      "Well I'm updating my last review. As previously stated gave them 2 stars because the food is somewhat good. I don't like dealing with the depressed people inside so I decided moving forward I would place the order online and pick up. \n",
      "When I arrived a few minutes after my pick up time they told me sorry your order is not ready, it will be faster if you stand in line. How is it faster if I stand in line when have had my order for 45minutes?! They told me it would be an additional 20 minutes to make my order but they could magically make it faster if I stood in line in 10 min before ordering the exact same thing they had on the receipt in front of them. No sense in coming back. I have tried time and time again, and every time it gets worse. This will be my last trip to place I at one point in my life came to weekly. So with this, so long cafe rio.\n",
      "For lunch or dinner, get the BBQ burger. One of the best I ever had. \n",
      "Great food, service, price and location.\n",
      "I had a great time today going to the barbecue restaurant. It is the first time of that I have been there, and the service is excellent much faster than I expected, and the food was delicious!\n",
      "Great place, Great Food, EXCELLENT CUSTOMER SERVICE!! We came in with 8 ppl they fixed us up a table and served us faster than Mc Donalds serves Fries! Great quality food... Everything is Great Great Great!!! If you haven't ate here its a MUST!!\n"
     ]
    }
   ],
   "source": [
    "print ('Most %s similar reviews:' % n)\n",
    "for review in returned_reviews:\n",
    "    print  (review )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search enginem makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying positive/negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Naive-Bayes Classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8092195831313621"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_nb.score(vectors_train, target_train) #accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8031250454433085"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_nb.score(vectors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Logistic Regression Classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lrc = LogisticRegression()\n",
    "model_lrc.fit(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8433446437227339"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_lrc.score(vectors_train, target_train) #accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8256940102083848"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_lrc.score(vectors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key features(words) that make the positive prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazing',\n",
       " 'best',\n",
       " 'incredible',\n",
       " 'delicious',\n",
       " 'awesome',\n",
       " 'thank',\n",
       " 'perfection',\n",
       " 'perfect',\n",
       " 'phenomenal',\n",
       " 'fantastic',\n",
       " 'favorite',\n",
       " 'great',\n",
       " 'perfectly',\n",
       " 'excellent',\n",
       " 'highly',\n",
       " 'die',\n",
       " 'heaven',\n",
       " 'gem',\n",
       " 'love',\n",
       " 'bomb']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find it out by ranking\n",
    "n = 20\n",
    "get_top_values(model_lrc.coef_[0], n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Key features(words) that make the negative prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'ok',\n",
       " 'horrible',\n",
       " 'rude',\n",
       " 'bland',\n",
       " 'terrible',\n",
       " 'okay',\n",
       " 'mediocre',\n",
       " 'slow',\n",
       " 'disappointing',\n",
       " 'dry',\n",
       " 'meh',\n",
       " 'lacking',\n",
       " 'unfortunately',\n",
       " 'overpriced',\n",
       " 'wasn',\n",
       " 'awful',\n",
       " 'average',\n",
       " 'poor',\n",
       " 'decent']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find it out by ranking\n",
    "n = 20\n",
    "get_bottom_values(model_lrc.coef_[0], n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=10,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=5, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rfc = RandomForestClassifier(max_depth = None,\n",
    "                                  n_estimators = 5,\n",
    "                                  min_samples_leaf = 10)\n",
    "model_rfc.fit(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8138826951042172"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_rfc.score(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7711305325713399"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_rfc.score(vectors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What features (words) are important by inspecting the RFC model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazing',\n",
       " 'great',\n",
       " 'love',\n",
       " 'best',\n",
       " 'awesome',\n",
       " 'delicious',\n",
       " 'bad',\n",
       " 'like',\n",
       " 'friendly',\n",
       " 'didn',\n",
       " 'horrible',\n",
       " 'favorite',\n",
       " 'highly',\n",
       " 'excellent',\n",
       " 'perfect',\n",
       " 'definitely',\n",
       " 'wasn',\n",
       " 'average',\n",
       " 'thank',\n",
       " 'worst']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "get_top_values(model_rfc.feature_importances_, n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cross validation to evaluate classifiers\n",
    "\n",
    "[sklearn cross validation](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(model_lrc, \n",
    "                           vectors_train,\n",
    "                           target_train,\n",
    "                            cv = 5,\n",
    "                            scoring = \"accuracy\"\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.826136643215901, 0.003967095258931436)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores.mean(), cv_scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use grid search to find best predictable classifier\n",
    "\n",
    "\n",
    "[sklearn grid search tutorial (with cross validation)](http://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n",
    "\n",
    "[sklearn grid search documentation (with cross validation)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "\n",
      "{'penalty': 'l2', 'C': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "0.554 (+/-0.004) for {'penalty': 'l1', 'C': 0.1}\n",
      "0.718 (+/-0.083) for {'penalty': 'l1', 'C': 100}\n",
      "0.552 (+/-0.012) for {'penalty': 'l2', 'C': 0.1}\n",
      "0.752 (+/-0.073) for {'penalty': 'l2', 'C': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.78      0.76    221181\n",
      "       True       0.73      0.69      0.71    191421\n",
      "\n",
      "avg / total       0.74      0.74      0.74    412602\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tune Logistic Regression Regularization parameter C and different penalty\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "param_grid = [{'penalty':['l1'], 'C':[0.1, 100]},\n",
    "              {'penalty':['l2'], 'C':[0.1, 100]}]\n",
    "\n",
    "scores = ['accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score + \"\\n\\n\")\n",
    "    clf = GridSearchCV(LogisticRegression(),\n",
    "                       param_grid,\n",
    "                       cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(vectors_train[:500,:], target_train[:500])\n",
    "    print(\"Best parameters set found on development set:\\n\\n\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\nGrid scores on development set:\\n\\n\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    \n",
    "    print(\"\\nDetailed classification report:\\n\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print(\"\\n\")\n",
    "    y_true, y_pred = target_test, clf.predict(vectors_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
