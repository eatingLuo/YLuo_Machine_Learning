{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese NLP Evaluation Project_Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Chinese NLP evaluation project finished by Yiting Luo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data is from: ChnSentiCorp: https://pan.baidu.com/s/1hsF1Zbm. Data includes negative and positive hotel evaluation.\n",
    "\n",
    "Testing data is split from training data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luoyiting/Desktop/nlpdatachallenge\n"
     ]
    }
   ],
   "source": [
    "# Change working directory\n",
    "import os\n",
    "os.chdir('/Users/luoyiting/Desktop/nlpdatachallenge')\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyiting/anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/luoyiting/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import jieba\n",
    "import codecs\n",
    "from langconv import * # convert Traditional Chinese characters to Simplified Chinese characters\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.core import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data from original folder\n",
    "dataBaseDirPos = \"ChnSentiCorp情感分析酒店评论/正面/\"\n",
    "dataBaseDirNeg = \"ChnSentiCorp情感分析酒店评论/负面/\"\n",
    "positiveFiles = [dataBaseDirPos + f for f in listdir(dataBaseDirPos) if isfile(join(dataBaseDirPos, f))]\n",
    "negativeFiles = [dataBaseDirNeg + f for f in listdir(dataBaseDirNeg) if isfile(join(dataBaseDirNeg, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "2001\n"
     ]
    }
   ],
   "source": [
    "# Check if our data is balanced\n",
    "print(len(positiveFiles))\n",
    "print(len(negativeFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge positive and negative comments and generate a data document\n",
    "documents = []\n",
    "for filename in positiveFiles:\n",
    "    text = \"\"\n",
    "    with codecs.open(filename, \"rb\") as doc_file:\n",
    "        for line in doc_file:\n",
    "            try:\n",
    "                line = line.decode(\"utf-8\")\n",
    "            except:\n",
    "                continue\n",
    "            text+=Converter('zh-hans').convert(line)# Convert from traditional to simplified Chinese\n",
    "\n",
    "            text = text.replace(\"\\n\", \"\")\n",
    "            text = text.replace(\"\\r\", \"\")\n",
    "    documents.append((text, \"pos\"))\n",
    "\n",
    "for filename in negativeFiles:\n",
    "    text = \"\"\n",
    "    with codecs.open(filename, \"rb\") as doc_file:\n",
    "        for line in doc_file:\n",
    "            try:\n",
    "                line = line.decode(\"utf-8\")\n",
    "            except:\n",
    "                continue\n",
    "            text+=Converter('zh-hans').convert(line)# Convert from traditional to simplified Chinese\n",
    "\n",
    "            text = text.replace(\"\\n\", \"\")\n",
    "            text = text.replace(\"\\r\", \"\")\n",
    "    documents.append((text, \"neg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset: documents\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare text and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/lp/xhvxtxys4f3b6nwg_3dcfkmw0000gn/T/jieba.cache\n",
      "Loading model cost 1.330 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and remove stop words\n",
    "totalX = []\n",
    "totalY = [str(doc[1]) for doc in documents]  #label: pos/neg\n",
    "stopwords = [ line.rstrip() for line in codecs.open('chinese_stop_words.txt',\"r\", encoding=\"utf-8\") ]\n",
    "for doc in documents:\n",
    "    seg_list = jieba.cut(doc[0], cut_all=False)\n",
    "    seg_list = list(seg_list)\n",
    "    final =[]\n",
    "    for seg in seg_list:\n",
    "        if seg not in stopwords:\n",
    "            final.append(seg)\n",
    "    totalX.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text: 4002\n",
      "Number of label: 4002\n"
     ]
    }
   ],
   "source": [
    "# Check if our text and target are balanced\n",
    "print(\"Number of text:\", len(totalX))\n",
    "print(\"Number of label:\", len(totalY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length is:  514\n"
     ]
    }
   ],
   "source": [
    "h = sorted([len(sentence) for sentence in totalX])\n",
    "maxLength = h[int(len(h))-1]\n",
    "print(\"Max length is: \",maxLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nup1FBwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11de98f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw a plot to see distribution of text_length\n",
    "fit = stats.norm.pdf(h, np.mean(h), np.std(h))  #fit text_length with a normal function\n",
    "pl.plot(h,fit,'-o')\n",
    "pl.hist(h,normed=True)      #draw histogram of text_length\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words to Number Tokens, padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalX = [\" \".join(str(wordslist)) for wordslist in totalX]  # Keras Tokenizer expect the words tokens to be seperated by space \n",
    "input_tokenizer = Tokenizer(30000) # Initial vocab size\n",
    "input_tokenizer.fit_on_texts(totalX)\n",
    "vocab_size = len(input_tokenizer.word_index) + 1\n",
    "print(\"input vocab_size:\",vocab_size)\n",
    "totalX = np.array(pad_sequences(input_tokenizer.texts_to_sequences(totalX), maxlen=maxLength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Output Label to 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output vocab_size: 3\n"
     ]
    }
   ],
   "source": [
    "target_tokenizer = Tokenizer(3)\n",
    "target_tokenizer.fit_on_texts(totalY)\n",
    "print(\"output vocab_size:\",len(target_tokenizer.word_index) + 1)\n",
    "totalY = np.array(target_tokenizer.texts_to_sequences(totalY)) -1\n",
    "totalY = totalY.reshape(totalY.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn output 0s and 1s to categories(one-hot vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalY = to_categorical(totalY, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dimen = totalY.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save meta data for later predition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maxLength: the input sequence length\n",
    "\n",
    "vocab_size: Input vocab size\n",
    "\n",
    "output_dimen: which is 2 in this example (pos or neg)\n",
    "\n",
    "sentiment_tag: either [\"neg\",\"pos\"] or [\"pos\",\"neg\"] matching the target tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_reverse_word_index = {v: k for k, v in list(target_tokenizer.word_index.items())}\n",
    "sentiment_tag = [target_reverse_word_index[1],target_reverse_word_index[2]] \n",
    "metaData = {\"maxLength\":maxLength,\"vocab_size\":vocab_size,\"output_dimen\":output_dimen,\"sentiment_tag\":sentiment_tag}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Neural Network Classifier Model, Train and Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 514, 256)          764160    \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 514, 256)          393984    \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 256)               393984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,552,642\n",
      "Trainable params: 1,552,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3601 samples, validate on 401 samples\n",
      "Epoch 1/20\n",
      "3601/3601 [==============================] - 530s 147ms/step - loss: 0.7013 - acc: 0.5099 - val_loss: 0.6956 - val_acc: 0.4963\n",
      "Epoch 2/20\n",
      "3601/3601 [==============================] - 522s 145ms/step - loss: 0.6908 - acc: 0.5437 - val_loss: 0.6832 - val_acc: 0.5860\n",
      "Epoch 3/20\n",
      "3601/3601 [==============================] - 482s 134ms/step - loss: 0.6594 - acc: 0.6026 - val_loss: 0.6500 - val_acc: 0.6209\n",
      "Epoch 4/20\n",
      "3601/3601 [==============================] - 497s 138ms/step - loss: 0.6025 - acc: 0.6865 - val_loss: 0.6027 - val_acc: 0.6733\n",
      "Epoch 5/20\n",
      "3601/3601 [==============================] - 484s 134ms/step - loss: 0.5682 - acc: 0.7148 - val_loss: 0.5748 - val_acc: 0.7132\n",
      "Epoch 6/20\n",
      "3601/3601 [==============================] - 489s 136ms/step - loss: 0.5275 - acc: 0.7448 - val_loss: 0.5631 - val_acc: 0.7207\n",
      "Epoch 7/20\n",
      "3601/3601 [==============================] - 494s 137ms/step - loss: 0.4975 - acc: 0.7623 - val_loss: 0.5350 - val_acc: 0.7556\n",
      "Epoch 8/20\n",
      "3601/3601 [==============================] - 488s 136ms/step - loss: 0.4718 - acc: 0.7762 - val_loss: 0.5208 - val_acc: 0.7606\n",
      "Epoch 9/20\n",
      "3601/3601 [==============================] - 486s 135ms/step - loss: 0.4561 - acc: 0.7970 - val_loss: 0.4853 - val_acc: 0.7880\n",
      "Epoch 10/20\n",
      "3601/3601 [==============================] - 497s 138ms/step - loss: 0.4523 - acc: 0.7998 - val_loss: 0.5298 - val_acc: 0.7257\n",
      "Epoch 11/20\n",
      "3601/3601 [==============================] - 492s 137ms/step - loss: 0.4440 - acc: 0.8051 - val_loss: 0.4975 - val_acc: 0.7930\n",
      "Epoch 12/20\n",
      "3601/3601 [==============================] - 485s 135ms/step - loss: 0.4113 - acc: 0.8162 - val_loss: 0.4901 - val_acc: 0.7830\n",
      "Epoch 13/20\n",
      "3601/3601 [==============================] - 485s 135ms/step - loss: 0.3799 - acc: 0.8398 - val_loss: 0.4740 - val_acc: 0.8105\n",
      "Epoch 14/20\n",
      "3601/3601 [==============================] - 485s 135ms/step - loss: 0.3713 - acc: 0.8437 - val_loss: 0.4287 - val_acc: 0.8080\n",
      "Epoch 15/20\n",
      "3601/3601 [==============================] - 484s 134ms/step - loss: 0.3368 - acc: 0.8570 - val_loss: 0.4211 - val_acc: 0.8354\n",
      "Epoch 16/20\n",
      "3601/3601 [==============================] - 478s 133ms/step - loss: 0.3176 - acc: 0.8709 - val_loss: 0.3820 - val_acc: 0.8579\n",
      "Epoch 17/20\n",
      "3601/3601 [==============================] - 480s 133ms/step - loss: 0.3221 - acc: 0.8678 - val_loss: 0.4370 - val_acc: 0.8155\n",
      "Epoch 18/20\n",
      "3601/3601 [==============================] - 481s 134ms/step - loss: 0.3833 - acc: 0.8356 - val_loss: 0.4090 - val_acc: 0.8279\n",
      "Epoch 19/20\n",
      "3601/3601 [==============================] - 479s 133ms/step - loss: 0.3081 - acc: 0.8770 - val_loss: 0.4319 - val_acc: 0.8329\n",
      "Epoch 20/20\n",
      "3601/3601 [==============================] - 478s 133ms/step - loss: 0.2828 - acc: 0.8861 - val_loss: 0.3887 - val_acc: 0.8504\n",
      "Saved model!\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim,input_length = maxLength))\n",
    "# Each input would have a size of (maxLength x 256) and each of these 256 sized vectors are fed into the GRU layer one at a time.\n",
    "# All the intermediate outputs are collected and then passed on to the second GRU layer.\n",
    "model.add(GRU(256, dropout=0.9, return_sequences=True))\n",
    "# Using the intermediate outputs, we pass them to another GRU layer and collect the final output only this time\n",
    "model.add(GRU(256, dropout=0.9))\n",
    "# The output is then sent to a fully connected layer that would give us our final output_dim classes\n",
    "model.add(Dense(output_dimen, activation='softmax'))\n",
    "# We use the adam optimizer instead of standard SGD since it converges much faster\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(totalX, totalY, validation_split=0.1, batch_size=32, epochs=20, verbose=1)\n",
    "model.save('sentiment_chinese_model.HDF5')\n",
    "\n",
    "print(\"Saved model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the training procedure above, we can see training accuracy keeps going up to 88.61%, while validation accuracy fluctuate around 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So accuracy of a Keras Neural network classifier is around 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
